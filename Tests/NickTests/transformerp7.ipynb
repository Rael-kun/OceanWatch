{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8738549,"sourceType":"datasetVersion","datasetId":5246239},{"sourceId":8781335,"sourceType":"datasetVersion","datasetId":5278472}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Now","metadata":{}},{"cell_type":"code","source":"# Imports\nimport numpy as np\nimport pandas as pd\nimport os\nimport sys\nimport pickle\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import LambdaLR\n\n# Imports for models used\nimport math\nimport logging\nimport pdb\n\nfrom numpy import linalg\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n# Utils\nimport random\nimport datetime\nimport socket\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:47:09.854809Z","iopub.execute_input":"2024-06-25T12:47:09.855215Z","iopub.status.idle":"2024-06-25T12:47:13.973290Z","shell.execute_reply.started":"2024-06-25T12:47:09.855184Z","shell.execute_reply":"2024-06-25T12:47:13.972038Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Utils before anything else","metadata":{}},{"cell_type":"code","source":"torch.pi = torch.acos(torch.zeros(1)).item()*2\n\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\n    \ndef new_log(logdir,filename):\n    \"\"\"Defines logging format.\n    \"\"\"\n    filename = os.path.join(logdir,\n                            datetime.datetime.now().strftime(\"log_%Y-%m-%d-%H-%M-%S_\"+socket.gethostname()+\"_\"+filename+\".log\"))\n    logging.basicConfig(level=logging.INFO,\n                        filename=filename,\n                        format=\"%(asctime)s - %(name)s - %(message)s\",\n                        filemode=\"w\")\n    console = logging.StreamHandler()\n    console.setLevel(logging.INFO)\n    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(message)s\")\n    console.setFormatter(formatter)\n    logging.getLogger('').addHandler(console)   \n    \ndef haversine(input_coords, \n               pred_coords):\n    \"\"\" Calculate the haversine distances between input_coords and pred_coords.\n    \n    Args:\n        input_coords, pred_coords: Tensors of size (...,N), with (...,0) and (...,1) are\n        the latitude and longitude in radians.\n    \n    Returns:\n        The havesine distances between\n    \"\"\"\n    R = 6371\n    lat_errors = pred_coords[...,0] - input_coords[...,0]\n    lon_errors = pred_coords[...,1] - input_coords[...,1]\n    a = torch.sin(lat_errors/2)**2\\\n        +torch.cos(input_coords[:,:,0])*torch.cos(pred_coords[:,:,0])*torch.sin(lon_errors/2)**2\n    c = 2*torch.atan2(torch.sqrt(a),torch.sqrt(1-a))\n    d = R*c\n    return d\n\ndef top_k_logits(logits, k):\n    v, ix = torch.topk(logits, k)\n    out = logits.clone()\n    out[out < v[:, [-1]]] = -float('Inf')\n    return out\n\ndef top_k_nearest_idx(att_logits, att_idxs, r_vicinity):\n    \"\"\"Keep only k values nearest the current idx.\n    \n    Args:\n        att_logits: a Tensor of shape (bachsize, data_size). \n        att_idxs: a Tensor of shape (bachsize, 1), indicates \n            the current idxs.\n        r_vicinity: number of values to be kept.\n    \"\"\"\n    device = att_logits.device\n    idx_range = torch.arange(att_logits.shape[-1]).to(device).repeat(att_logits.shape[0],1)\n    idx_dists = torch.abs(idx_range - att_idxs)\n    out = att_logits.clone()\n    out[idx_dists >= r_vicinity/2] = -float('Inf')\n    return out","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:47:13.975699Z","iopub.execute_input":"2024-06-25T12:47:13.976156Z","iopub.status.idle":"2024-06-25T12:47:14.043567Z","shell.execute_reply.started":"2024-06-25T12:47:13.976126Z","shell.execute_reply":"2024-06-25T12:47:14.042281Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"class Config():\n    retrain = True\n    tb_log = False\n    # TP6 - Changed\n    #device = torch.device(\"cuda:0\")\n    device = torch.device(\"cpu\")\n    \n    max_epochs = 50\n    batch_size = 32\n    n_samples = 16\n    \n    init_seqlen = 18\n    max_seqlen = 120\n    min_seqlen = 36\n    \n    # TP6 - Changed\n    dataset_name = \"centerdirectory\"\n\n    # TP6 - Changed\n    if dataset_name == \"centerdirectory\": #==============================\n   \n        # When mode == \"grad\" or \"pos_grad\", sog and cog are actually dlat and \n        # dlon    \n        lat_size = 250\n        lon_size = 270\n        sog_size = 30\n        cog_size = 72\n\n        \n        n_lat_embd = 256\n        n_lon_embd = 256\n        n_sog_embd = 128\n        n_cog_embd = 128\n    \n        # don't forget to update\n        lat_min = 53.4\n        lat_max = 66.2\n        lon_min = 9.4\n        lon_max = 30.5\n\n    \n    #===========================================================================\n    # Model and sampling flags\n    mode = \"pos\"  #\"pos\", \"pos_grad\", \"mlp_pos\", \"mlpgrid_pos\", \"velo\", \"grid_l2\", \"grid_l1\", \n                            # \"ce_vicinity\", \"gridcont_grid\", \"gridcont_real\", \"gridcont_gridsin\", \"gridcont_gridsigmoid\"\n    sample_mode =  \"pos_vicinity\" # \"pos\", \"pos_vicinity\" or \"velo\"\n    top_k = 10 # int or None \n    r_vicinity = 40 # int\n    \n    # Blur flags\n    #===================================================\n    blur = True\n    blur_learnable = False\n    blur_loss_w = 1.0\n    blur_n = 2\n    if not blur:\n        blur_n = 0\n        blur_loss_w = 0\n    \n    # Data flags\n    #===================================================\n    #Updated for me :)     # TP6 - Changed\n    datadir = f\"/kaggle/input/{dataset_name}/\"\n    trainset_name = \"marinedata_train.pkl\"\n    validset_name = \"marinedata_val.pkl\"\n    testset_name = \"marinedata_test.pkl\"\n    \n    \n    # model parameters\n    #===================================================\n    n_head = 8\n    n_layer = 8\n    full_size = lat_size + lon_size + sog_size + cog_size\n    n_embd = n_lat_embd + n_lon_embd + n_sog_embd + n_cog_embd\n    # base GPT config, params common to all GPT versions\n    embd_pdrop = 0.1\n    resid_pdrop = 0.1\n    attn_pdrop = 0.1\n    \n    # optimization parameters\n    #===================================================\n    learning_rate = 6e-4 # 6e-4\n    betas = (0.9, 0.95)\n    grad_norm_clip = 1.0\n    weight_decay = 0.1 # only applied on matmul weights\n    # learning rate decay params: linear warmup followed by cosine decay to 10% of original\n    lr_decay = True\n    warmup_tokens = 512*20 # these two numbers come from the GPT-3 paper, but may not be good defaults elsewhere\n    final_tokens = 260e9 # (at what point we reach 10% of original LR)\n    num_workers = 4 # for DataLoader\n    \n    filename = f\"{dataset_name}\"\\\n        + f\"-{mode}-{sample_mode}-{top_k}-{r_vicinity}\"\\\n        + f\"-blur-{blur}-{blur_learnable}-{blur_n}-{blur_loss_w}\"\\\n        + f\"-data_size-{lat_size}-{lon_size}-{sog_size}-{cog_size}\"\\\n        + f\"-embd_size-{n_lat_embd}-{n_lon_embd}-{n_sog_embd}-{n_cog_embd}\"\\\n        + f\"-head-{n_head}-{n_layer}\"\\\n        + f\"-bs-{batch_size}\"\\\n        + f\"-lr-{learning_rate}\"\\\n        + f\"-seqlen-{init_seqlen}-{max_seqlen}\"\n    savedir = \"./results/\"+filename+\"/\"\n    \n    ckpt_path = os.path.join(savedir,\"model.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:47:14.045081Z","iopub.execute_input":"2024-06-25T12:47:14.045443Z","iopub.status.idle":"2024-06-25T12:47:14.061733Z","shell.execute_reply.started":"2024-06-25T12:47:14.045397Z","shell.execute_reply":"2024-06-25T12:47:14.060408Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Init","metadata":{}},{"cell_type":"code","source":"class AISDataset(Dataset):\n    \"\"\"Customized Pytorch dataset.\n    \"\"\"\n    def __init__(self, \n                 l_data, \n                 max_seqlen=96,\n                 dtype=torch.float32,\n                 device=torch.device(\"cpu\")):\n        \"\"\"\n        Args\n            l_data: list of dictionaries, each element is an AIS trajectory. \n                l_data[idx][\"mmsi\"]: vessel's MMSI.\n                l_data[idx][\"traj\"]: a matrix whose columns are \n                    [LAT, LON, SOG, COG, TIMESTAMP]\n                lat, lon, sog, and cod have been standardized, i.e. range = [0,1).\n            max_seqlen: (optional) max sequence length. Default is\n        \"\"\"    \n            \n        self.max_seqlen = max_seqlen\n        self.device = device\n        \n        self.l_data = l_data \n\n    def __len__(self):\n        return len(self.l_data)\n        \n    def __getitem__(self, idx):\n        \"\"\"Gets items.\n        \n        Returns:\n            seq: Tensor of (max_seqlen, [lat,lon,sog,cog]).\n            mask: Tensor of (max_seqlen, 1). mask[i] = 0.0 if x[i] is a\n            padding.\n            seqlen: sequence length.\n            mmsi: vessel's MMSI.\n            time_start: timestamp of the starting time of the trajectory.\n        \"\"\"\n        V = self.l_data[idx]\n        m_v = V[\"traj\"][:,:4] # lat, lon, sog, cog\n#         m_v[m_v==1] = 0.9999\n        m_v[m_v>0.9999] = 0.9999\n        seqlen = min(len(m_v), self.max_seqlen)\n        seq = np.zeros((self.max_seqlen,4))\n        seq[:seqlen,:] = m_v[:seqlen,:]\n        seq = torch.tensor(seq, dtype=torch.float32)\n        \n        mask = torch.zeros(self.max_seqlen)\n        mask[:seqlen] = 1.\n        \n        seqlen = torch.tensor(seqlen, dtype=torch.int)\n        mmsi =  torch.tensor(V[\"mmsi\"], dtype=torch.int)\n        time_start = torch.tensor(V[\"traj\"][0,4], dtype=torch.int)\n        \n        return seq , mask, seqlen, mmsi, time_start\n    \nclass AISDataset_grad(Dataset):\n    \"\"\"Customized Pytorch dataset.\n    Return the positions and the gradient of the positions.\n    \"\"\"\n    def __init__(self, \n                 l_data, \n                 dlat_max=0.04,\n                 dlon_max=0.04,\n                 max_seqlen=96,\n                 dtype=torch.float32,\n                 device=torch.device(\"cpu\")):\n        \"\"\"\n        Args\n            l_data: list of dictionaries, each element is an AIS trajectory. \n                l_data[idx][\"mmsi\"]: vessel's MMSI.\n                l_data[idx][\"traj\"]: a matrix whose columns are \n                    [LAT, LON, SOG, COG, TIMESTAMP]\n                lat, lon, sog, and cod have been standardized, i.e. range = [0,1).\n            dlat_max, dlon_max: the maximum value of the gradient of the positions.\n                dlat_max = max(lat[idx+1]-lat[idx]) for all idx.\n            max_seqlen: (optional) max sequence length. Default is\n        \"\"\"    \n            \n        self.dlat_max = dlat_max\n        self.dlon_max = dlon_max\n        self.dpos_max = np.array([dlat_max, dlon_max])\n        self.max_seqlen = max_seqlen\n        self.device = device\n        \n        self.l_data = l_data \n\n    def __len__(self):\n        return len(self.l_data)\n        \n    def __getitem__(self, idx):\n        \"\"\"Gets items.\n        \n        Returns:\n            seq: Tensor of (max_seqlen, [lat,lon,sog,cog]).\n            mask: Tensor of (max_seqlen, 1). mask[i] = 0.0 if x[i] is a\n            padding.\n            seqlen: sequence length.\n            mmsi: vessel's MMSI.\n            time_start: timestamp of the starting time of the trajectory.\n        \"\"\"\n        V = self.l_data[idx]\n        m_v = V[\"traj\"][:,:4] # lat, lon, sog, cog\n        m_v[m_v==1] = 0.9999\n        seqlen = min(len(m_v), self.max_seqlen)\n        seq = np.zeros((self.max_seqlen,4))\n        # lat and lon\n        seq[:seqlen,:2] = m_v[:seqlen,:2] \n        # dlat and dlon\n        dpos = (m_v[1:,:2]-m_v[:-1,:2]+self.dpos_max )/(2*self.dpos_max )\n        dpos = np.concatenate((dpos[:1,:],dpos),axis=0)\n        dpos[dpos>=1] = 0.9999\n        dpos[dpos<=0] = 0.0\n        seq[:seqlen,2:] = dpos[:seqlen,:2] \n        \n        # convert to Tensor\n        seq = torch.tensor(seq, dtype=torch.float32)\n        \n        mask = torch.zeros(self.max_seqlen)\n        mask[:seqlen] = 1.\n        \n        seqlen = torch.tensor(seqlen, dtype=torch.int)\n        mmsi =  torch.tensor(V[\"mmsi\"], dtype=torch.int)\n        time_start = torch.tensor(V[\"traj\"][0,4], dtype=torch.int)\n        \n        return seq , mask, seqlen, mmsi, time_start","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:47:14.063637Z","iopub.execute_input":"2024-06-25T12:47:14.064031Z","iopub.status.idle":"2024-06-25T12:47:14.090552Z","shell.execute_reply.started":"2024-06-25T12:47:14.063986Z","shell.execute_reply":"2024-06-25T12:47:14.089345Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Models Used","metadata":{}},{"cell_type":"code","source":"logger = logging.getLogger(__name__)\n\n\nclass CausalSelfAttention(nn.Module):\n    \"\"\"\n    A vanilla multi-head masked self-attention layer with a projection at the end.\n    It is possible to use torch.nn.MultiheadAttention here but I am including an\n    explicit implementation here to show that there is nothing too scary here.\n    \"\"\"\n\n    def __init__(self, config):\n        super().__init__()\n        assert config.n_embd % config.n_head == 0\n        # key, query, value projections for all heads\n        self.key = nn.Linear(config.n_embd, config.n_embd)\n        self.query = nn.Linear(config.n_embd, config.n_embd)\n        self.value = nn.Linear(config.n_embd, config.n_embd)\n        # regularization\n        self.attn_drop = nn.Dropout(config.attn_pdrop)\n        self.resid_drop = nn.Dropout(config.resid_pdrop)\n        # output projection\n        self.proj = nn.Linear(config.n_embd, config.n_embd)\n        # causal mask to ensure that attention is only applied to the left in the input sequence\n        self.register_buffer(\"mask\", torch.tril(torch.ones(config.max_seqlen, config.max_seqlen))\n                                     .view(1, 1, config.max_seqlen, config.max_seqlen))\n        self.n_head = config.n_head\n\n    def forward(self, x, layer_past=None):\n        B, T, C = x.size()\n\n        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n        k = self.key(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n        q = self.query(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n        v = self.value(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n\n        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n        att = att.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf'))\n        att = F.softmax(att, dim=-1)\n        att = self.attn_drop(att)\n        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n\n        # output projection\n        y = self.resid_drop(self.proj(y))\n        return y\n\nclass Block(nn.Module):\n    \"\"\" an unassuming Transformer block \"\"\"\n\n    def __init__(self, config):\n        super().__init__()\n        self.ln1 = nn.LayerNorm(config.n_embd)\n        self.ln2 = nn.LayerNorm(config.n_embd)\n        self.attn = CausalSelfAttention(config)\n        self.mlp = nn.Sequential(\n            nn.Linear(config.n_embd, 4 * config.n_embd),\n            nn.GELU(),\n            nn.Linear(4 * config.n_embd, config.n_embd),\n            nn.Dropout(config.resid_pdrop),\n        )\n\n    def forward(self, x):\n        x = x + self.attn(self.ln1(x))\n        x = x + self.mlp(self.ln2(x))\n        return x\n\nclass TrAISformer(nn.Module):\n    \"\"\"Transformer for AIS trajectories.\"\"\"\n\n    def __init__(self, config, partition_model = None):\n        super().__init__()\n\n        self.lat_size = config.lat_size\n        self.lon_size = config.lon_size\n        self.sog_size = config.sog_size\n        self.cog_size = config.cog_size\n        self.full_size = config.full_size\n        self.n_lat_embd = config.n_lat_embd\n        self.n_lon_embd = config.n_lon_embd\n        self.n_sog_embd = config.n_sog_embd\n        self.n_cog_embd = config.n_cog_embd\n        self.register_buffer(\n            \"att_sizes\", \n            torch.tensor([config.lat_size, config.lon_size, config.sog_size, config.cog_size]))\n        self.register_buffer(\n            \"emb_sizes\", \n            torch.tensor([config.n_lat_embd, config.n_lon_embd, config.n_sog_embd, config.n_cog_embd]))\n        \n        if hasattr(config,\"partition_mode\"):\n            self.partition_mode = config.partition_mode\n        else:\n            self.partition_mode = \"uniform\"\n        self.partition_model = partition_model\n        \n        if hasattr(config,\"blur\"):\n            self.blur = config.blur\n            self.blur_learnable = config.blur_learnable\n            self.blur_loss_w = config.blur_loss_w\n            self.blur_n = config.blur_n\n            if self.blur:\n                self.blur_module = nn.Conv1d(1, 1, 3, padding = 1, padding_mode = 'replicate', groups=1, bias=False)\n                if not self.blur_learnable:\n                    for params in self.blur_module.parameters():\n                        params.requires_grad = False\n                        params.fill_(1/3)\n            else:\n                self.blur_module = None\n                \n        \n        if hasattr(config,\"lat_min\"): # the ROI is provided.\n            self.lat_min = config.lat_min\n            self.lat_max = config.lat_max\n            self.lon_min = config.lon_min\n            self.lon_max = config.lon_max\n            self.lat_range = config.lat_max-config.lat_min\n            self.lon_range = config.lon_max-config.lon_min\n            self.sog_range = 30.\n            \n        if hasattr(config,\"mode\"): # mode: \"pos\" or \"velo\".\n            # \"pos\": predict directly the next positions.\n            # \"velo\": predict the velocities, use them to \n            # calculate the next positions.\n            self.mode = config.mode\n        else:\n            self.mode = \"pos\"\n    \n\n        # Passing from the 4-D space to a high-dimentional space\n        self.lat_emb = nn.Embedding(self.lat_size, config.n_lat_embd)\n        self.lon_emb = nn.Embedding(self.lon_size, config.n_lon_embd)\n        self.sog_emb = nn.Embedding(self.sog_size, config.n_sog_embd)\n        self.cog_emb = nn.Embedding(self.cog_size, config.n_cog_embd)\n            \n            \n        self.pos_emb = nn.Parameter(torch.zeros(1, config.max_seqlen, config.n_embd))\n        self.drop = nn.Dropout(config.embd_pdrop)\n        \n        # transformer\n        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])\n        \n        \n        # decoder head\n        self.ln_f = nn.LayerNorm(config.n_embd)\n        if self.mode in (\"mlp_pos\",\"mlp\"):\n            self.head = nn.Linear(config.n_embd, config.n_embd, bias=False)\n        else:\n            self.head = nn.Linear(config.n_embd, self.full_size, bias=False) # Classification head\n            \n        self.max_seqlen = config.max_seqlen\n        self.apply(self._init_weights)\n\n        logger.info(\"number of parameters: %e\", sum(p.numel() for p in self.parameters()))\n\n    def get_max_seqlen(self):\n        return self.max_seqlen\n\n    def _init_weights(self, module):\n        if isinstance(module, (nn.Linear, nn.Embedding)):\n            module.weight.data.normal_(mean=0.0, std=0.02)\n            if isinstance(module, nn.Linear) and module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n\n    def configure_optimizers(self, train_config):\n        \"\"\"\n        This long function is unfortunately doing something very simple and is being very defensive:\n        We are separating out all parameters of the model into two buckets: those that will experience\n        weight decay for regularization and those that won't (biases, and layernorm/embedding weights).\n        We are then returning the PyTorch optimizer object.\n        \"\"\"\n\n        # separate out all parameters to those that will and won't experience regularizing weight decay\n        decay = set()\n        no_decay = set()\n        whitelist_weight_modules = (torch.nn.Linear, torch.nn.Conv1d)\n        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n        for mn, m in self.named_modules():\n            for pn, p in m.named_parameters():\n                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name\n\n                if pn.endswith('bias'):\n                    # all biases will not be decayed\n                    no_decay.add(fpn)\n                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n                    # weights of whitelist modules will be weight decayed\n                    decay.add(fpn)\n                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n                    # weights of blacklist modules will NOT be weight decayed\n                    no_decay.add(fpn)\n\n        # special case the position embedding parameter in the root GPT module as not decayed\n        no_decay.add('pos_emb')\n\n        # validate that we considered every parameter\n        param_dict = {pn: p for pn, p in self.named_parameters()}\n        inter_params = decay & no_decay\n        union_params = decay | no_decay\n        assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n        assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n                                                    % (str(param_dict.keys() - union_params), )\n\n        # create the pytorch optimizer object\n        optim_groups = [\n            {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n            {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},\n        ]\n        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)\n        return optimizer\n   \n    \n    def to_indexes(self, x, mode=\"uniform\"):\n        \"\"\"Convert tokens to indexes.\n        \n        Args:\n            x: a Tensor of size (batchsize, seqlen, 4). x has been truncated \n                to [0,1).\n            model: currenly only supports \"uniform\".\n        \n        Returns:\n            idxs: a Tensor (dtype: Long) of indexes.\n        \"\"\"\n        bs, seqlen, data_dim = x.shape\n        if mode == \"uniform\":\n            idxs = (x*self.att_sizes).long()\n            return idxs, idxs\n        elif mode in (\"freq\", \"freq_uniform\"):\n            \n            idxs = (x*self.att_sizes).long()\n            idxs_uniform = idxs.clone()\n            discrete_lats, discrete_lons, lat_ids, lon_ids = self.partition_model(x[:,:,:2])\n#             pdb.set_trace()\n            idxs[:,:,0] = torch.round(lat_ids.reshape((bs,seqlen))).long()\n            idxs[:,:,1] = torch.round(lon_ids.reshape((bs,seqlen))).long()                               \n            return idxs, idxs_uniform\n    \n    \n    def forward(self, x, masks = None, with_targets=False, return_loss_tuple=False):\n        \"\"\"\n        Args:\n            x: a Tensor of size (batchsize, seqlen, 4). x has been truncated \n                to [0,1).\n            masks: a Tensor of the same size of x. masks[idx] = 0. if \n                x[idx] is a padding.\n            with_targets: if True, inputs = x[:,:-1,:], targets = x[:,1:,:], \n                otherwise inputs = x.\n        Returns: \n            logits, loss\n        \"\"\"\n        \n        if self.mode in (\"mlp_pos\",\"mlp\",):\n            idxs, idxs_uniform = x, x # use the real-values of x.\n        else:            \n            # Convert to indexes\n            idxs, idxs_uniform = self.to_indexes(x, mode=self.partition_mode)\n        \n        if with_targets:\n            inputs = idxs[:,:-1,:].contiguous()\n            targets = idxs[:,1:,:].contiguous()\n            targets_uniform = idxs_uniform[:,1:,:].contiguous()\n            inputs_real = x[:,:-1,:].contiguous()\n            targets_real = x[:,1:,:].contiguous()\n        else:\n            inputs_real = x\n            inputs = idxs\n            targets = None\n            \n        batchsize, seqlen, _ = inputs.size()\n        assert seqlen <= self.max_seqlen, \"Cannot forward, model block size is exhausted.\"\n\n        # forward the GPT model\n        lat_embeddings = self.lat_emb(inputs[:,:,0]) # (bs, seqlen, lat_size)\n        lon_embeddings = self.lon_emb(inputs[:,:,1]) \n        sog_embeddings = self.sog_emb(inputs[:,:,2]) \n        cog_embeddings = self.cog_emb(inputs[:,:,3])      \n        token_embeddings = torch.cat((lat_embeddings, lon_embeddings, sog_embeddings, cog_embeddings),dim=-1)\n            \n        position_embeddings = self.pos_emb[:, :seqlen, :] # each position maps to a (learnable) vector (1, seqlen, n_embd)\n        fea = self.drop(token_embeddings + position_embeddings)\n        fea = self.blocks(fea)\n        fea = self.ln_f(fea) # (bs, seqlen, n_embd)\n        logits = self.head(fea) # (bs, seqlen, full_size) or (bs, seqlen, n_embd)\n        \n        lat_logits, lon_logits, sog_logits, cog_logits =\\\n            torch.split(logits, (self.lat_size, self.lon_size, self.sog_size, self.cog_size), dim=-1)\n        \n        # Calculate the loss\n        loss = None\n        loss_tuple = None\n        if targets is not None:\n\n            sog_loss = F.cross_entropy(sog_logits.view(-1, self.sog_size), \n                                       targets[:,:,2].view(-1), \n                                       reduction=\"none\").view(batchsize,seqlen)\n            cog_loss = F.cross_entropy(cog_logits.view(-1, self.cog_size), \n                                       targets[:,:,3].view(-1), \n                                       reduction=\"none\").view(batchsize,seqlen)\n            lat_loss = F.cross_entropy(lat_logits.view(-1, self.lat_size), \n                                       targets[:,:,0].view(-1), \n                                       reduction=\"none\").view(batchsize,seqlen)\n            lon_loss = F.cross_entropy(lon_logits.view(-1, self.lon_size), \n                                       targets[:,:,1].view(-1), \n                                       reduction=\"none\").view(batchsize,seqlen)                     \n\n            if self.blur:\n                lat_probs = F.softmax(lat_logits, dim=-1) \n                lon_probs = F.softmax(lon_logits, dim=-1)\n                sog_probs = F.softmax(sog_logits, dim=-1)\n                cog_probs = F.softmax(cog_logits, dim=-1)\n\n                for _ in range(self.blur_n):\n                    blurred_lat_probs = self.blur_module(lat_probs.reshape(-1,1,self.lat_size)).reshape(lat_probs.shape)\n                    blurred_lon_probs = self.blur_module(lon_probs.reshape(-1,1,self.lon_size)).reshape(lon_probs.shape)\n                    blurred_sog_probs = self.blur_module(sog_probs.reshape(-1,1,self.sog_size)).reshape(sog_probs.shape)\n                    blurred_cog_probs = self.blur_module(cog_probs.reshape(-1,1,self.cog_size)).reshape(cog_probs.shape)\n\n                    blurred_lat_loss = F.nll_loss(blurred_lat_probs.view(-1, self.lat_size),\n                                                  targets[:,:,0].view(-1),\n                                                  reduction=\"none\").view(batchsize,seqlen)\n                    blurred_lon_loss = F.nll_loss(blurred_lon_probs.view(-1, self.lon_size),\n                                                  targets[:,:,1].view(-1),\n                                                  reduction=\"none\").view(batchsize,seqlen)\n                    blurred_sog_loss = F.nll_loss(blurred_sog_probs.view(-1, self.sog_size),\n                                                  targets[:,:,2].view(-1),\n                                                  reduction=\"none\").view(batchsize,seqlen)\n                    blurred_cog_loss = F.nll_loss(blurred_cog_probs.view(-1, self.cog_size),\n                                                  targets[:,:,3].view(-1),\n                                                  reduction=\"none\").view(batchsize,seqlen)\n\n                    lat_loss += self.blur_loss_w*blurred_lat_loss\n                    lon_loss += self.blur_loss_w*blurred_lon_loss\n                    sog_loss += self.blur_loss_w*blurred_sog_loss\n                    cog_loss += self.blur_loss_w*blurred_cog_loss\n\n                    lat_probs = blurred_lat_probs\n                    lon_probs = blurred_lon_probs\n                    sog_probs = blurred_sog_probs\n                    cog_probs = blurred_cog_probs\n                    \n\n            loss_tuple = (lat_loss, lon_loss, sog_loss, cog_loss)\n            loss = sum(loss_tuple)\n        \n            if masks is not None:\n                loss = (loss*masks).sum(dim=1)/masks.sum(dim=1)\n        \n            loss = loss.mean()\n        \n        if return_loss_tuple:\n            return logits, loss, loss_tuple\n        else:\n            return logits, loss","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:47:14.093934Z","iopub.execute_input":"2024-06-25T12:47:14.094295Z","iopub.status.idle":"2024-06-25T12:47:14.175622Z","shell.execute_reply.started":"2024-06-25T12:47:14.094264Z","shell.execute_reply":"2024-06-25T12:47:14.174367Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Reqs\nchannels:\n  - pytorch\n  - conda-forge\n  - defaults\ndependencies:\n  - _libgcc_mutex=0.1=main\n  - _openmp_mutex=4.5=1_gnu\n  - _py-xgboost-mutex=2.0=cpu_0\n  - aiohttp=3.7.4.post0=py37h5e8e339_0\n  - argon2-cffi=20.1.0=py37h27cfd23_1\n  - async-timeout=3.0.1=py_1000\n  - async_generator=1.10=py37h28b3542_0\n  - attrs=20.3.0=pyhd3eb1b0_0\n  - blas=1.0=mkl\n  - bleach=3.3.0=pyhd3eb1b0_0\n  - blinker=1.4=py_1\n  - bokeh=2.3.3=py37h89c1867_0\n  - bottleneck=1.3.2=py37h161383b_2\n  - brotlipy=0.7.0=py37h27cfd23_1003\n  - c-ares=1.17.1=h27cfd23_0\n  - ca-certificates=2021.5.30=ha878542_0\n  - catalogue=1.0.0=py37_1\n  - catboost=0.26=py37h89c1867_0\n  - certifi=2021.5.30=py37h89c1867_0\n  - cffi=1.14.5=py37h261ae71_0\n  - cftime=1.5.0=py37h6323ea4_0\n  - chardet=4.0.0=py37h06a4308_1003\n  - cloudpickle=1.6.0=py_0\n  - confuse=1.4.0=pyhd3eb1b0_0\n  - cryptography=3.4.7=py37hd23ed53_0\n  - cudatoolkit=9.2=0\n  - curl=7.71.1=hbc83047_1\n  - cycler=0.10.0=py37_0\n  - cymem=2.0.5=py37h2531618_0\n  - cython-blis=0.7.4=py37h27cfd23_1\n  - cytoolz=0.9.0.1=py37h14c3975_1\n  - dask=2021.7.2=pyhd8ed1ab_0\n  - dask-core=2021.7.2=pyhd8ed1ab_0\n  - dataclasses=0.8=pyhc8e2a94_3\n  - decorator=5.0.5=pyhd3eb1b0_0\n  - defusedxml=0.7.1=pyhd3eb1b0_0\n  - dill=0.2.9=py37_0\n  - distributed=2021.7.2=py37h89c1867_0\n  - entrypoints=0.3=py37_0\n  - freetype=2.10.4=h5ab3b9f_0\n  - fsspec=2021.7.0=pyhd8ed1ab_0\n  - future=0.18.2=py37h89c1867_3\n  - hdf4=4.2.13=h3ca952b_2\n  - hdf5=1.10.6=hb1b8bf9_0\n  - heapdict=1.0.1=py_0\n  - htmlmin=0.1.12=pyhd3eb1b0_1\n  - idna=2.10=pyhd3eb1b0_0\n  - imagehash=4.2.0=pyhd3eb1b0_0\n  - imbalanced-learn=0.8.0=pyhd8ed1ab_0\n  - importlib-metadata=3.7.3=py37h06a4308_1\n  - importlib_metadata=3.7.3=hd3eb1b0_1\n  - intel-openmp=2020.2=254\n  - ipykernel=5.3.4=py37h5ca1d4c_0\n  - ipython=5.8.0=py37_1\n  - ipython_genutils=0.2.0=pyhd3eb1b0_1\n  - ipywidgets=7.5.1=pyh9f0ad1d_1\n  - jinja2=2.11.3=pyhd3eb1b0_0\n  - jpeg=9b=h024ee3a_2\n  - json5=0.9.5=py_0\n  - jsonschema=3.0.2=py37_0\n  - jupyter_client=6.1.12=pyhd3eb1b0_0\n  - jupyter_core=4.7.1=py37h06a4308_0\n  - jupyterlab=2.2.6=py_0\n  - jupyterlab_pygments=0.1.2=py_0\n  - jupyterlab_server=1.2.0=py_0\n  - kiwisolver=1.3.1=py37h2531618_0\n  - krb5=1.18.2=h173b8e3_0\n  - lcms2=2.12=h3be6417_0\n  - ld_impl_linux-64=2.33.1=h53a641e_7\n  - libcurl=7.71.1=h20c2e04_1\n  - libedit=3.1.20210216=h27cfd23_1\n  - libffi=3.3=he6710b0_2\n  - libgcc-ng=9.3.0=h5101ec6_17\n  - libgfortran-ng=7.3.0=hdf63c60_0\n  - libgomp=9.3.0=h5101ec6_17\n  - libllvm10=10.0.1=hbcb73fb_5\n  - libnetcdf=4.6.1=h2053bdc_4\n  - libpng=1.6.37=hbc83047_0\n  - libprotobuf=3.17.2=h4ff587b_1\n  - libsodium=1.0.18=h7b6447c_0\n  - libssh2=1.9.0=h1ba5d50_1\n  - libstdcxx-ng=9.1.0=hdf63c60_0\n  - libtiff=4.1.0=h2733197_1\n  - libxgboost=1.3.3=h2531618_0\n  - lightgbm=3.1.1=py37h2531618_0\n  - llvmlite=0.36.0=py37h612dafd_4\n  - locket=0.2.0=py_2\n  - lz4-c=1.9.3=h2531618_0\n  - markupsafe=1.1.1=py37h14c3975_1\n  - matplotlib=3.3.2=0\n  - matplotlib-base=3.3.2=py37h817c723_0\n  - missingno=0.4.2=pyhd3eb1b0_1\n  - mistune=0.8.4=py37h14c3975_1001\n  - mkl=2020.2=256\n  - mkl-service=2.3.0=py37he8ac12f_0\n  - mkl_fft=1.3.0=py37h54f3939_0\n  - mkl_random=1.1.1=py37h0573a6f_0\n  - msgpack-numpy=0.4.7.1=pyhd3eb1b0_0\n  - msgpack-python=1.0.2=py37hff7bd54_1\n  - multidict=5.1.0=py37h5e8e339_1\n  - murmurhash=1.0.5=py37h2531618_0\n  - nb_conda=2.2.1=py37_0\n  - nb_conda_kernels=2.3.1=py37h06a4308_0\n  - nbclient=0.5.3=pyhd3eb1b0_0\n  - nbconvert=6.0.7=py37_0\n  - nbformat=5.1.3=pyhd3eb1b0_0\n  - ncurses=6.2=he6710b0_1\n  - nest-asyncio=1.5.1=pyhd3eb1b0_0\n  - netcdf4=1.5.7=py37h0a24e14_0\n  - networkx=2.5=py_0\n  - ninja=1.10.2=py37hff7bd54_0\n  - notebook=6.3.0=py37h06a4308_0\n  - numba=0.53.1=py37ha9443f7_0\n  - numpy=1.19.2=py37h54aff64_0\n  - numpy-base=1.19.2=py37hfa32c7d_0\n  - olefile=0.46=py37_0\n  - openssl=1.1.1k=h7f98852_0\n  - packaging=20.9=pyhd3eb1b0_0\n  - pandas=1.2.3=py37ha9443f7_0\n  - pandas-profiling=2.9.0=pyhd3eb1b0_0\n  - pandoc=2.12=h06a4308_0\n  - pandocfilters=1.4.3=py37h06a4308_1\n  - partd=1.2.0=pyhd8ed1ab_0\n  - pexpect=4.8.0=pyhd3eb1b0_3\n  - phik=0.11.2=pyhd3eb1b0_1\n  - pickleshare=0.7.5=pyhd3eb1b0_1003\n  - pillow=8.2.0=py37he98fc37_0\n  - pip=21.0.1=py37h06a4308_0\n  - plac=1.1.0=py37_1\n  - preshed=3.0.2=py37he6710b0_1\n  - proj=7.0.1=h59a7b90_1\n  - prometheus_client=0.10.0=pyhd3eb1b0_0\n  - prompt_toolkit=1.0.15=py37_0\n  - psutil=5.8.0=py37h27cfd23_1\n  - ptyprocess=0.7.0=pyhd3eb1b0_2\n  - py-xgboost=1.3.3=py37h06a4308_0\n  - pyasn1=0.4.8=py_0\n  - pycparser=2.20=py_2\n  - pydeprecate=0.3.1=pyhd8ed1ab_0\n  - pygments=2.8.1=pyhd3eb1b0_0\n  - pyjwt=2.1.0=pyhd8ed1ab_0\n  - pyopenssl=20.0.1=pyhd3eb1b0_1\n  - pyparsing=2.4.7=pyhd3eb1b0_0\n  - pyproj=2.6.1.post1=py37h61f852b_1\n  - pyrsistent=0.17.3=py37h7b6447c_0\n  - pysocks=1.7.1=py37_1\n  - python=3.7.9=h7579374_0\n  - python-dateutil=2.8.1=pyhd3eb1b0_0\n  - python_abi=3.7=1_cp37m\n  - pytorch=1.6.0=py3.7_cuda9.2.148_cudnn7.6.3_0\n  - pytorch-lightning=1.4.4=pyhd8ed1ab_0\n  - pytz=2021.1=pyhd3eb1b0_0\n  - pyu2f=0.1.5=pyhd8ed1ab_0\n  - pywavelets=1.1.1=py37h7b6447c_2\n  - pyzmq=20.0.0=py37h2531618_1\n  - readline=8.1=h27cfd23_0\n  - requests=2.25.1=pyhd3eb1b0_0\n  - requests-oauthlib=1.3.0=pyh9f0ad1d_0\n  - seaborn=0.11.1=pyhd3eb1b0_0\n  - send2trash=1.5.0=pyhd3eb1b0_1\n  - setuptools=52.0.0=py37h06a4308_0\n  - simplegeneric=0.8.1=py37_2\n  - six=1.15.0=py37h06a4308_0\n  - sortedcontainers=2.4.0=pyhd8ed1ab_0\n  - spacy=2.3.5=py37hff7bd54_0\n  - sqlite=3.35.4=hdfb4753_0\n  - srsly=1.0.5=py37h2531618_0\n  - tangled-up-in-unicode=0.1.0=pyhd3eb1b0_0\n  - tbb=2020.3=hfd86e86_0\n  - tblib=1.7.0=pyhd8ed1ab_0\n  - tensorboard-data-server=0.6.0=py37h7f0c10b_0\n  - terminado=0.9.4=py37h06a4308_0\n  - testpath=0.4.4=pyhd3eb1b0_0\n  - thinc=7.4.5=py37h9a67853_0\n  - threadpoolctl=2.1.0=pyh5ca1d4c_0\n  - tk=8.6.10=hbc83047_0\n  - toolz=0.11.1=pyhd3eb1b0_0\n  - torchmetrics=0.5.0=pyhd8ed1ab_0\n  - torchtext=0.7.0=py37\n  - torchvision=0.7.0=py37_cu92\n  - tornado=6.1=py37h27cfd23_0\n  - traitlets=5.0.5=pyhd3eb1b0_0\n  - typing-extensions=3.10.0.0=hd8ed1ab_0\n  - typing_extensions=3.10.0.0=pyha770c72_0\n  - ujson=4.0.2=py37h2531618_0\n  - visions=0.5.0=pyhd3eb1b0_0\n  - wasabi=0.8.2=pyhd3eb1b0_0\n  - wcwidth=0.2.5=py_0\n  - webencodings=0.5.1=py37_1\n  - wheel=0.36.2=pyhd3eb1b0_0\n  - widgetsnbextension=3.5.1=py37_0\n  - wrapt=1.12.1=py37h7b6447c_1\n  - xarray=0.19.0=pyhd8ed1ab_1\n  - xgboost=1.3.3=py37h06a4308_0\n  - xz=5.2.5=h7b6447c_0\n  - yaml=0.2.5=h7b6447c_0\n  - yarl=1.6.3=py37h5e8e339_2\n  - zeromq=4.3.4=h2531618_0\n  - zict=2.0.0=py_0\n  - zlib=1.2.11=h7b6447c_3\n  - zstd=1.4.9=haebb681_0\n  - pip:\n    - absl-py==0.10.0\n    - addict==2.3.0\n    - aiohttp-cors==0.7.0\n    - aioredis==1.3.1\n    - blessings==1.7\n    - boltons==20.2.1\n    - cachetools==4.1.1\n    - click==7.1.2\n    - colorama==0.4.4\n    - colorful==0.5.4\n    - de-core-news-sm==2.0.0\n    - dm-tree==0.1.5\n    - einops==0.3.0\n    - en-core-web-sm==2.0.0\n    - filelock==3.0.12\n    - fire==0.4.0\n    - google-api-core==1.26.3\n    - google-auth==1.22.1\n    - google-auth-oauthlib==0.4.1\n    - googleapis-common-protos==1.53.0\n    - gpustat==0.6.0\n    - grpcio==1.32.0\n    - hiredis==2.0.0\n    - joblib==0.17.0\n    - lambda-networks==0.4.0\n    - markdown==3.3\n    - nltk==3.5\n    - nvidia-ml-py3==7.352.0\n    - oauthlib==3.1.0\n    - opencensus==0.7.12\n    - opencensus-context==0.1.2\n    - opencv-python==4.4.0.44\n    - pathspec==0.8.0\n    - protobuf==3.13.0\n    - py-spy==0.3.5\n    - pyasn1-modules==0.2.8\n    - pyyaml==5.4.1\n    - ray==1.2.0\n    - redis==3.5.3\n    - regex==2020.11.13\n    - rsa==4.6\n    - scikit-learn==0.23.2\n    - scipy==1.5.2\n    - sdeint==0.2.1\n    - sklearn==0.0\n    - tabulate==0.8.9\n    - tensorboard==2.3.0\n    - tensorboard-plugin-wit==1.7.0\n    - termcolor==1.1.0\n    - torchsde==0.2.1\n    - tqdm==4.50.2\n    - trampoline==0.1.2\n    - urllib3==1.25.10\n    - werkzeug==1.0.1\n    - zipp==3.3.0","metadata":{}},{"cell_type":"markdown","source":"# Trainers/ Evaluation metrics for model to improve","metadata":{}},{"cell_type":"code","source":"logger = logging.getLogger(__name__)\n\n\n@torch.no_grad()\ndef sample(model,\n           seqs,\n           steps,\n           temperature=1.0,\n           sample=False,\n           sample_mode=\"pos_vicinity\",\n           r_vicinity=20,\n           top_k=None):\n    \"\"\"\n    Take a conditoning sequence of AIS observations seq and predict the next observation,\n    feed the predictions back into the model each time. \n    \"\"\"\n    max_seqlen = model.get_max_seqlen()\n    model.eval()\n    for k in range(steps):\n        seqs_cond = seqs if seqs.size(1) <= max_seqlen else seqs[:, -max_seqlen:]  # crop context if needed\n\n        # logits.shape: (batch_size, seq_len, data_size)\n        logits, _ = model(seqs_cond)\n        d2inf_pred = torch.zeros((logits.shape[0], 4)).to(seqs.device) + 0.5\n\n        # pluck the logits at the final step and scale by temperature\n        logits = logits[:, -1, :] / temperature  # (batch_size, data_size)\n\n        lat_logits, lon_logits, sog_logits, cog_logits = \\\n            torch.split(logits, (model.lat_size, model.lon_size, model.sog_size, model.cog_size), dim=-1)\n\n        # optionally crop probabilities to only the top k options\n        if sample_mode in (\"pos_vicinity\",):\n            idxs, idxs_uniform = model.to_indexes(seqs_cond[:, -1:, :])\n            lat_idxs, lon_idxs = idxs_uniform[:, 0, 0:1], idxs_uniform[:, 0, 1:2]\n            lat_logits = top_k_nearest_idx(lat_logits, lat_idxs, r_vicinity)\n            lon_logits = top_k_nearest_idx(lon_logits, lon_idxs, r_vicinity)\n\n        if top_k is not None:\n            lat_logits = top_k_logits(lat_logits, top_k)\n            lon_logits = top_k_logits(lon_logits, top_k)\n            sog_logits = top_k_logits(sog_logits, top_k)\n            cog_logits = top_k_logits(cog_logits, top_k)\n\n        # apply softmax to convert to probabilities\n        lat_probs = F.softmax(lat_logits, dim=-1)\n        lon_probs = F.softmax(lon_logits, dim=-1)\n        sog_probs = F.softmax(sog_logits, dim=-1)\n        cog_probs = F.softmax(cog_logits, dim=-1)\n\n        # sample from the distribution or take the most likely\n        if sample:\n            lat_ix = torch.multinomial(lat_probs, num_samples=1)  # (batch_size, 1)\n            lon_ix = torch.multinomial(lon_probs, num_samples=1)\n            sog_ix = torch.multinomial(sog_probs, num_samples=1)\n            cog_ix = torch.multinomial(cog_probs, num_samples=1)\n        else:\n            _, lat_ix = torch.topk(lat_probs, k=1, dim=-1)\n            _, lon_ix = torch.topk(lon_probs, k=1, dim=-1)\n            _, sog_ix = torch.topk(sog_probs, k=1, dim=-1)\n            _, cog_ix = torch.topk(cog_probs, k=1, dim=-1)\n\n        ix = torch.cat((lat_ix, lon_ix, sog_ix, cog_ix), dim=-1)\n        # convert to x (range: [0,1))\n        x_sample = (ix.float() + d2inf_pred) / model.att_sizes\n\n        # append to the sequence and continue\n        seqs = torch.cat((seqs, x_sample.unsqueeze(1)), dim=1)\n\n    return seqs\n\n\nclass TrainerConfig:\n    # optimization parameters\n    max_epochs = 10\n    batch_size = 64\n    learning_rate = 3e-4\n    betas = (0.9, 0.95)\n    grad_norm_clip = 1.0\n    weight_decay = 0.1  # only applied on matmul weights\n    # learning rate decay params: linear warmup followed by cosine decay to 10% of original\n    lr_decay = False\n    warmup_tokens = 375e6  # these two numbers come from the GPT-3 paper, but may not be good defaults elsewhere\n    final_tokens = 260e9  # (at what point we reach 10% of original LR)\n    # checkpoint settings\n    ckpt_path = None\n    num_workers = 0  # for DataLoader\n\n    def __init__(self, **kwargs):\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n\n\nclass Trainer:\n\n    def __init__(self, model, train_dataset, test_dataset, config, savedir=None, device=torch.device(\"cpu\"), aisdls={},\n                 INIT_SEQLEN=0):\n        self.train_dataset = train_dataset\n        self.test_dataset = test_dataset\n        self.config = config\n        self.savedir = savedir\n\n        self.device = device\n        self.model = model.to(device)\n        self.aisdls = aisdls\n        self.INIT_SEQLEN = INIT_SEQLEN\n\n    def save_checkpoint(self, best_epoch):\n        # DataParallel wrappers keep raw model object in .module attribute\n        raw_model = self.model.module if hasattr(self.model, \"module\") else self.model\n        #         logging.info(\"saving %s\", self.config.ckpt_path)\n        logging.info(f\"Best epoch: {best_epoch:03d}, saving model to {self.config.ckpt_path}\")\n        torch.save(raw_model.state_dict(), self.config.ckpt_path)\n\n    def train(self):\n        model, config, aisdls, INIT_SEQLEN, = self.model, self.config, self.aisdls, self.INIT_SEQLEN\n        raw_model = model.module if hasattr(self.model, \"module\") else model\n        optimizer = raw_model.configure_optimizers(config)\n        if model.mode in (\"gridcont_gridsin\", \"gridcont_gridsigmoid\", \"gridcont2_gridsigmoid\",):\n            return_loss_tuple = True\n        else:\n            return_loss_tuple = False\n\n        def run_epoch(split, epoch=0):\n            is_train = split == 'Training'\n            model.train(is_train)\n            data = self.train_dataset if is_train else self.test_dataset\n            loader = DataLoader(data, shuffle=True, pin_memory=True,\n                                batch_size=config.batch_size,\n                                num_workers=config.num_workers)\n\n            losses = []\n            n_batches = len(loader)\n            pbar = tqdm(enumerate(loader), total=len(loader)) if is_train else enumerate(loader)\n            d_loss, d_reg_loss, d_n = 0, 0, 0\n            for it, (seqs, masks, seqlens, mmsis, time_starts) in pbar:\n\n                # place data on the correct device\n                seqs = seqs.to(self.device)\n                masks = masks[:, :-1].to(self.device)\n\n                # forward the model\n                with torch.set_grad_enabled(is_train):\n                    if return_loss_tuple:\n                        logits, loss, loss_tuple = model(seqs,\n                                                         masks=masks,\n                                                         with_targets=True,\n                                                         return_loss_tuple=return_loss_tuple)\n                    else:\n                        logits, loss = model(seqs, masks=masks, with_targets=True)\n                    loss = loss.mean()  # collapse all losses if they are scattered on multiple gpus\n                    losses.append(loss.item())\n\n                d_loss += loss.item() * seqs.shape[0]\n                if return_loss_tuple:\n                    reg_loss = loss_tuple[-1]\n                    reg_loss = reg_loss.mean()\n                    d_reg_loss += reg_loss.item() * seqs.shape[0]\n                d_n += seqs.shape[0]\n                if is_train:\n\n                    # backprop and update the parameters\n                    model.zero_grad()\n                    loss.backward()\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)\n                    optimizer.step()\n\n                    # decay the learning rate based on our progress\n                    if config.lr_decay:\n                        self.tokens += (\n                                seqs >= 0).sum()  # number of tokens processed this step (i.e. label is not -100)\n                        if self.tokens < config.warmup_tokens:\n                            # linear warmup\n                            lr_mult = float(self.tokens) / float(max(1, config.warmup_tokens))\n                        else:\n                            # cosine learning rate decay\n                            progress = float(self.tokens - config.warmup_tokens) / float(\n                                max(1, config.final_tokens - config.warmup_tokens))\n                            lr_mult = max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress)))\n                        lr = config.learning_rate * lr_mult\n                        for param_group in optimizer.param_groups:\n                            param_group['lr'] = lr\n                    else:\n                        lr = config.learning_rate\n\n                    # report progress\n                    pbar.set_description(f\"epoch {epoch + 1} iter {it}: loss {loss.item():.5f}. lr {lr:e}\")\n\n                    # tb logging\n                    if TB_LOG:\n                        tb.add_scalar(\"loss\",\n                                      loss.item(),\n                                      epoch * n_batches + it)\n                        tb.add_scalar(\"lr\",\n                                      lr,\n                                      epoch * n_batches + it)\n\n                        for name, params in model.head.named_parameters():\n                            tb.add_histogram(f\"head.{name}\", params, epoch * n_batches + it)\n                            tb.add_histogram(f\"head.{name}.grad\", params.grad, epoch * n_batches + it)\n                        if model.mode in (\"gridcont_real\",):\n                            for name, params in model.res_pred.named_parameters():\n                                tb.add_histogram(f\"res_pred.{name}\", params, epoch * n_batches + it)\n                                tb.add_histogram(f\"res_pred.{name}.grad\", params.grad, epoch * n_batches + it)\n\n            if is_train:\n                if return_loss_tuple:\n                    logging.info(\n                        f\"{split}, epoch {epoch + 1}, loss {d_loss / d_n:.5f}, {d_reg_loss / d_n:.5f}, lr {lr:e}.\")\n                else:\n                    logging.info(f\"{split}, epoch {epoch + 1}, loss {d_loss / d_n:.5f}, lr {lr:e}.\")\n            else:\n                if return_loss_tuple:\n                    logging.info(f\"{split}, epoch {epoch + 1}, loss {d_loss / d_n:.5f}.\")\n                else:\n                    logging.info(f\"{split}, epoch {epoch + 1}, loss {d_loss / d_n:.5f}.\")\n\n            if not is_train:\n                test_loss = float(np.mean(losses))\n                #                 logging.info(\"test loss: %f\", test_loss)\n                return test_loss\n\n        best_loss = float('inf')\n        self.tokens = 0  # counter used for learning rate decay\n        best_epoch = 0\n\n        for epoch in range(config.max_epochs):\n\n            run_epoch('Training', epoch=epoch)\n            if self.test_dataset is not None:\n                test_loss = run_epoch('Valid', epoch=epoch)\n\n            # supports early stopping based on the test loss, or just save always if no test set is provided\n            good_model = self.test_dataset is None or test_loss < best_loss\n            if self.config.ckpt_path is not None and good_model:\n                best_loss = test_loss\n                best_epoch = epoch\n                self.save_checkpoint(best_epoch + 1)\n\n            ## SAMPLE AND PLOT\n            # ==========================================================================================\n            # ==========================================================================================\n            raw_model = model.module if hasattr(self.model, \"module\") else model\n            # TP6 - Change\n            seqs, masks, seqlens, mmsis, time_starts = next(iter(aisdls[\"test\"]))\n            n_plots = 7\n            init_seqlen = INIT_SEQLEN\n            seqs_init = seqs[:n_plots, :init_seqlen, :].to(self.device)\n            preds = sample(raw_model,\n                           seqs_init,\n                           96 - init_seqlen,\n                           temperature=1.0,\n                           sample=True,\n                           sample_mode=self.config.sample_mode,\n                           r_vicinity=self.config.r_vicinity,\n                           top_k=self.config.top_k)\n\n            img_path = os.path.join(self.savedir, f'epoch_{epoch + 1:03d}.jpg')\n            plt.figure(figsize=(9, 6), dpi=150)\n            cmap = plt.cm.get_cmap(\"jet\")\n            preds_np = preds.detach().cpu().numpy()\n            inputs_np = seqs.detach().cpu().numpy()\n            for idx in range(n_plots):\n                c = cmap(float(idx) / (n_plots))\n                try:\n                    seqlen = seqlens[idx].item()\n                except:\n                    continue\n                plt.plot(inputs_np[idx][:init_seqlen, 1], inputs_np[idx][:init_seqlen, 0], color=c)\n                plt.plot(inputs_np[idx][:init_seqlen, 1], inputs_np[idx][:init_seqlen, 0], \"o\", markersize=3, color=c)\n                plt.plot(inputs_np[idx][:seqlen, 1], inputs_np[idx][:seqlen, 0], linestyle=\"-.\", color=c)\n                plt.plot(preds_np[idx][init_seqlen:, 1], preds_np[idx][init_seqlen:, 0], \"x\", markersize=4, color=c)\n            plt.xlim([-0.05, 1.05])\n            plt.ylim([-0.05, 1.05])\n            plt.savefig(img_path, dpi=150)\n            plt.close()\n\n        # Final state\n        raw_model = self.model.module if hasattr(self.model, \"module\") else self.model\n        #         logging.info(\"saving %s\", self.config.ckpt_path)\n        logging.info(f\"Last epoch: {epoch:03d}, saving model to {self.config.ckpt_path}\")\n        save_path = self.config.ckpt_path.replace(\"model.pt\", f\"model_{epoch + 1:03d}.pt\")\n        torch.save(raw_model.state_dict(), save_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:47:14.177902Z","iopub.execute_input":"2024-06-25T12:47:14.178394Z","iopub.status.idle":"2024-06-25T12:47:14.241061Z","shell.execute_reply.started":"2024-06-25T12:47:14.178352Z","shell.execute_reply":"2024-06-25T12:47:14.239786Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Actual TrAISformer model","metadata":{}},{"cell_type":"code","source":"cf = Config()\nTB_LOG = cf.tb_log\nif TB_LOG:\n    from torch.utils.tensorboard import SummaryWriter\n\n    tb = SummaryWriter()\n\n# make deterministic- reproducible results\nset_seed(42)\ntorch.pi = torch.acos(torch.zeros(1)).item() * 2\n\nif __name__ == \"__main__\":\n\n    device = cf.device\n    init_seqlen = cf.init_seqlen\n\n    ## Logging\n    # ===============================\n    if not os.path.isdir(cf.savedir):\n        os.makedirs(cf.savedir)\n        print('======= Create directory to store trained models: ' + cf.savedir)\n    else:\n        print('======= Directory to store trained models: ' + cf.savedir)\n    new_log(cf.savedir, \"log\")\n\n    ## Data\n    # ===============================\n    moving_threshold = 0.05\n    l_pkl_filenames = [cf.trainset_name, cf.validset_name, cf.testset_name]\n    Data, aisdatasets, aisdls = {}, {}, {}\n    for phase, filename in zip((\"train\", \"valid\", \"test\"), l_pkl_filenames):\n        datapath = os.path.join(cf.datadir, filename)\n        print(f\"Loading {datapath}...\")\n        with open(datapath, \"rb\") as f:\n            l_pred_errors = pickle.load(f)\n        for V in l_pred_errors.values():\n            try:\n                moving_idx = np.where(V[\"traj\"][:, 2] > moving_threshold)[0][0]\n            except:\n                moving_idx = len(V[\"traj\"]) - 1  # This track will be removed\n            V[\"traj\"] = V[\"traj\"][moving_idx:, :]\n        Data[phase] = [x for x in l_pred_errors.values() if not np.isnan(x[\"traj\"]).any() and len(x[\"traj\"]) > cf.min_seqlen]\n        print(len(l_pred_errors), len(Data[phase]))\n        print(f\"Length: {len(Data[phase])}\")\n        print(\"Creating pytorch dataset...\")\n        # Latter in this scipt, we will use inputs = x[:-1], targets = x[1:], hence\n        # max_seqlen = cf.max_seqlen + 1.\n        if cf.mode in (\"pos_grad\", \"grad\"):\n            aisdatasets[phase] = AISDataset_grad(Data[phase],\n                                                          max_seqlen=cf.max_seqlen + 1,\n                                                          device=cf.device)\n        else:\n            aisdatasets[phase] = AISDataset(Data[phase],\n                                                     max_seqlen=cf.max_seqlen + 1,\n                                                     device=cf.device)\n        if phase == \"test\":\n            shuffle = False\n        else:\n            shuffle = True\n        aisdls[phase] = DataLoader(aisdatasets[phase],\n                                   batch_size=cf.batch_size,\n                                   shuffle=shuffle)\n    cf.final_tokens = 2 * len(aisdatasets[\"train\"]) * cf.max_seqlen\n\n    ## Model\n    # ===============================\n    print(\"Running model...\")\n    model = TrAISformer(cf, partition_model=None)\n\n    ## Trainer\n    # ===============================\n    print(\"Running trainer...\")\n    trainer = Trainer(\n        model, aisdatasets[\"train\"], aisdatasets[\"valid\"], cf, savedir=cf.savedir, device=cf.device, aisdls=aisdls, INIT_SEQLEN=init_seqlen)\n\n    ## Training\n    # ===============================\n    if cf.retrain:\n        trainer.train()\n\n    ## Evaluation\n    # ===============================\n    # Load the best model\n    print(\"Loading best model...\")\n    model.load_state_dict(torch.load(cf.ckpt_path))\n\n    v_ranges = torch.tensor([2, 3, 0, 0]).to(cf.device)\n    v_roi_min = torch.tensor([model.lat_min, -7, 0, 0]).to(cf.device)\n    max_seqlen = init_seqlen + 6 * 4\n\n    model.eval()\n    l_min_errors, l_mean_errors, l_masks = [], [], []\n    pbar = tqdm(enumerate(aisdls[\"test\"]), total=len(aisdls[\"test\"]))\n    with torch.no_grad():\n        for it, (seqs, masks, seqlens, mmsis, time_starts) in pbar:\n            seqs_init = seqs[:, :init_seqlen, :].to(cf.device)\n            masks = masks[:, :max_seqlen].to(cf.device)\n            batchsize = seqs.shape[0]\n            error_ens = torch.zeros((batchsize, max_seqlen - cf.init_seqlen, cf.n_samples)).to(cf.device)\n            for i_sample in range(cf.n_samples):\n                preds = sample(model,\n                                        seqs_init,\n                                        max_seqlen - init_seqlen,\n                                        temperature=1.0,\n                                        sample=True,\n                                        sample_mode=cf.sample_mode,\n                                        r_vicinity=cf.r_vicinity,\n                                        top_k=cf.top_k)\n                inputs = seqs[:, :max_seqlen, :].to(cf.device)\n                input_coords = (inputs * v_ranges + v_roi_min) * torch.pi / 180\n                pred_coords = (preds * v_ranges + v_roi_min) * torch.pi / 180\n                d = haversine(input_coords, pred_coords) * masks\n                error_ens[:, :, i_sample] = d[:, cf.init_seqlen:]\n            # Accumulation through batches\n            l_min_errors.append(error_ens.min(dim=-1))\n            l_mean_errors.append(error_ens.mean(dim=-1))\n            l_masks.append(masks[:, cf.init_seqlen:])\n\n    l_min = [x.values for x in l_min_errors]\n    m_masks = torch.cat(l_masks, dim=0)\n    min_errors = torch.cat(l_min, dim=0) * m_masks\n    pred_errors = min_errors.sum(dim=0) / m_masks.sum(dim=0)\n    pred_errors = pred_errors.detach().cpu().numpy()\n\n    ## Plot\n    # ===============================\n    plt.figure(figsize=(9, 6), dpi=150)\n    v_times = np.arange(len(pred_errors)) / 6\n    plt.plot(v_times, pred_errors)\n\n    timestep = 6\n    plt.plot(1, pred_errors[timestep], \"o\")\n    plt.plot([1, 1], [0, pred_errors[timestep]], \"r\")\n    plt.plot([0, 1], [pred_errors[timestep], pred_errors[timestep]], \"r\")\n    plt.text(1.12, pred_errors[timestep] - 0.5, \"{:.4f}\".format(pred_errors[timestep]), fontsize=10)\n\n    timestep = 12\n    plt.plot(2, pred_errors[timestep], \"o\")\n    plt.plot([2, 2], [0, pred_errors[timestep]], \"r\")\n    plt.plot([0, 2], [pred_errors[timestep], pred_errors[timestep]], \"r\")\n    plt.text(2.12, pred_errors[timestep] - 0.5, \"{:.4f}\".format(pred_errors[timestep]), fontsize=10)\n\n    timestep = 18\n    plt.plot(3, pred_errors[timestep], \"o\")\n    plt.plot([3, 3], [0, pred_errors[timestep]], \"r\")\n    plt.plot([0, 3], [pred_errors[timestep], pred_errors[timestep]], \"r\")\n    plt.text(3.12, pred_errors[timestep] - 0.5, \"{:.4f}\".format(pred_errors[timestep]), fontsize=10)\n    plt.xlabel(\"Time (hours)\")\n    plt.ylabel(\"Prediction errors (km)\")\n    plt.xlim([0, 12])\n    plt.ylim([0, 20])\n    # plt.ylim([0,pred_errors.max()+0.5])\n    plt.savefig(cf.savedir + \"prediction_error.png\")","metadata":{"execution":{"iopub.status.busy":"2024-06-25T13:39:35.453916Z","iopub.execute_input":"2024-06-25T13:39:35.454431Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"======= Directory to store trained models: ./results/centerdirectory-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/\nLoading /kaggle/input/centerdirectory/marinedata_train.pkl...\n11479 6830\nLength: 6830\nCreating pytorch dataset...\nLoading /kaggle/input/centerdirectory/marinedata_val.pkl...\n11479 7383\nLength: 7383\nCreating pytorch dataset...\nLoading /kaggle/input/centerdirectory/marinedata_test.pkl...\n11479 7287\nLength: 7287\nCreating pytorch dataset...\nRunning model...\n","output_type":"stream"},{"name":"stderr","text":"2024-06-25 13:39:37,466 - __main__ - number of parameters: 5.742055e+07\n2024-06-25 13:39:37,466 - __main__ - number of parameters: 5.742055e+07\n","output_type":"stream"},{"name":"stdout","text":"Running trainer...\n","output_type":"stream"},{"name":"stderr","text":"epoch 1 iter 213: loss 4.22636. lr 5.992133e-04: 100%|██████████| 214/214 [43:18<00:00, 12.14s/it]\n2024-06-25 14:22:56,302 - root - Training, epoch 1, loss 9.33557, lr 5.992133e-04.\n2024-06-25 14:22:56,302 - root - Training, epoch 1, loss 9.33557, lr 5.992133e-04.\n2024-06-25 14:38:36,551 - root - Valid, epoch 1, loss 3.32880.\n2024-06-25 14:38:36,551 - root - Valid, epoch 1, loss 3.32880.\n2024-06-25 14:38:36,559 - root - Best epoch: 001, saving model to ./results/centerdirectory-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/model.pt\n2024-06-25 14:38:36,559 - root - Best epoch: 001, saving model to ./results/centerdirectory-pos-pos_vicinity-10-40-blur-True-False-2-1.0-data_size-250-270-30-72-embd_size-256-256-128-128-head-8-8-bs-32-lr-0.0006-seqlen-18-120/model.pt\n/tmp/ipykernel_33/278629306.py:260: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  cmap = plt.cm.get_cmap(\"jet\")\nepoch 2 iter 75: loss 1.59871. lr 9.078087e-05:  36%|███▌      | 76/214 [15:24<28:37, 12.45s/it]","output_type":"stream"}]}]}